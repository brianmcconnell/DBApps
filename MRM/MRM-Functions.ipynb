{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2bcbc04-0863-4405-a375-6b6ad1a00017",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "import mlflow\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('./tmpl'))  # or the appropriate relative/absolute path\n",
    "\n",
    "import tmpl\n",
    "\n",
    "from mrm_utils import *\n",
    "from mrm_objects import *\n",
    "from mrm import *\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21627262-8257-4b23-9890-e71d6917674a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# submit_api_call\n",
    "No Longer Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1bb9a74-354d-4ca3-ad4b-063e8a19c7ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def submit_api_call(url):\n",
    "    try:\n",
    "        response = requests.get(url=url)#, headers=headers)\n",
    "        response.raise_for_status()  # this will raise an error if the request failed\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Request to {url} failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        data = (\n",
    "            response.json()\n",
    "        )  # this will raise an error if the response isn't valid JSON\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Failed to decode JSON from response: {e}\")\n",
    "        raise\n",
    "\n",
    "    if \"error_code\" in data:\n",
    "        raise Exception(f\"Error while retrieving content, [{data}]\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d82d3503-3227-4597-93d7-8433597e0112",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# extract_run_libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e56bd33-793e-493f-8e4f-2e42560f7f63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    def extract_run_libraries(run_tags):\n",
    "        \"\"\"\n",
    "        Extracting the list of libraries captured with mlflow experiment.\n",
    "        Note that MLFlow will struggle to capture notebook scoped libraries (using %pip install).\n",
    "        We highly recommend the use of cluster scope libraries for heightened governance\n",
    "        :param run_tags: The list of key /value tags captured by MLFlow\n",
    "        :return: The list of libraries\n",
    "        \"\"\"\n",
    "        libraries_objects = []\n",
    "        if 'mlflow.databricks.cluster.libraries' in run_tags:\n",
    "            libraries = json.loads(run_tags['mlflow.databricks.cluster.libraries'])\n",
    "            for installable in libraries['installable']:\n",
    "                library_type = list(installable.keys())[0]\n",
    "                library_coord = installable[library_type]\n",
    "                if library_type == 'maven':\n",
    "                    library_coord = library_coord['coordinates']\n",
    "                    libraries_objects.append(Library('maven', library_coord))\n",
    "            for redacted in libraries['redacted']:\n",
    "                library_type = list(redacted.keys())[0]\n",
    "                library_coord = redacted[library_type]\n",
    "                if library_type == 'maven':\n",
    "                    library_coord = library_coord['coordinates']\n",
    "                    libraries_objects.append(Library('maven', library_coord))\n",
    "        return Libraries(libraries_objects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bdd4a49-2e5a-420f-8c4d-a86ba9ead0ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# extract_run_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93dc84fd-0636-45e7-908e-bb59c63bd51f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_run_cluster(run_tags):\n",
    "        \"\"\"\n",
    "        Extracting cluster information as captured by MLFlow. This tag (stored as JSON string) seems to capture\n",
    "        all information required without the need to pull additional information from cluster API.\n",
    "        :param run_tags: The list of key /value tags captured by MLFlow\n",
    "        :return: cluster information such as name, DBR and instance type\n",
    "        \"\"\"\n",
    "        cluster_info = run_tags.get('mlflow.databricks.cluster.info') or None\n",
    "        if cluster_info:\n",
    "            cluster_info = json.loads(cluster_info)\n",
    "            autoscale = cluster_info.get('autoscale') or None\n",
    "            if autoscale:\n",
    "                num_workers = f'{autoscale.get(\"min_workers\")}-{autoscale.get(\"max_workers\")}'\n",
    "            else:\n",
    "                num_workers = cluster_info.get('autoscale') or None\n",
    "            return ExperimentCluster(\n",
    "                cluster_info.get('cluster_name') or None,\n",
    "                cluster_info.get('spark_version') or None,\n",
    "                cluster_info.get('node_type_id') or None,\n",
    "                num_workers\n",
    "            )\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f5e2d9a-7046-4355-88a3-ee57f2e50ce6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# extract_run_data_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa5dbb2d-5ea8-4a51-b36c-c778398a115c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    def extract_run_data_sources(run_object, run_tags):\n",
    "        \"\"\"\n",
    "        Simply extract all data sources captured by MLFlow. Data sources are captured as comma separated entries.\n",
    "        :param run_object: The list of key /value tags captured by MLFlow\n",
    "        :return: The list of data sources captured by MLFlow\n",
    "        \"\"\"\n",
    "        mlflow_data_records = []\n",
    "        if 'inputs' in run_object:\n",
    "            inputs = run_object['inputs']\n",
    "            if 'dataset_inputs' in inputs and len(inputs['dataset_inputs']) > 0:\n",
    "                for dataset_input in inputs['dataset_inputs']:\n",
    "                    dataset = dataset_input['dataset']\n",
    "                    if dataset['source_type'] == 'delta_table':\n",
    "                        delta_record = json.loads(dataset['source'])\n",
    "                        mlflow_data_records.append(ExperimentDataSource(\n",
    "                            delta_record['delta_table_name'],\n",
    "                            'delta',\n",
    "                            dataset['name'].split('@')[-1],\n",
    "                        ))\n",
    "                    else:\n",
    "                        mlflow_data_records.append(ExperimentDataSource(\n",
    "                            dataset['name'].split('@')[0],\n",
    "                            dataset['source_type'],\n",
    "                            dataset['name'].split('@')[-1],\n",
    "                        ))\n",
    "        else:\n",
    "            mlflow_data = run_tags.get('sparkDatasourceInfo') or None\n",
    "            if mlflow_data:\n",
    "                for source_record in mlflow_data.split('\\n'):\n",
    "                    source_record_dict = {}\n",
    "                    source_record_kv_pairs = source_record.split(',')\n",
    "                    for source_record_kv in source_record_kv_pairs:\n",
    "                        kv = source_record_kv.split('=')\n",
    "                        source_record_dict[kv[0]] = kv[1]\n",
    "\n",
    "                    name = source_record_dict.get('path') or None\n",
    "                    fmt = source_record_dict.get('format') or None\n",
    "                    version = source_record_dict.get('version') or None\n",
    "\n",
    "                    mlflow_data_records.append(ExperimentDataSource(\n",
    "                        name,\n",
    "                        fmt,\n",
    "                        version,\n",
    "                    ))\n",
    "\n",
    "        if len(mlflow_data_records) > 0:\n",
    "            return ExperimentDataSources(mlflow_data_records)\n",
    "        else:\n",
    "            return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87135955-4bde-4e4c-af2f-3f0e58319932",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# extract_run_artifact_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff9ea0e0-1aa5-4ba8-8d5d-8a711d7c1b09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    def extract_run_artifact_signature(fields):\n",
    "        \"\"\"\n",
    "        Return model input and output signature, as captured by MLFlow or manually registered by end user.\n",
    "        We extract the field name and type for each input or output feature we can later represent as a graph\n",
    "        :param fields: The input or output fields, stored as JSON string in MLFlow tag.\n",
    "        :return: The parsed field in the form of [name:type]\n",
    "        \"\"\"\n",
    "        fields = json.loads(fields)\n",
    "        parameters = []\n",
    "        for field in fields:\n",
    "            if field['type'] == 'tensor':\n",
    "                tensor_type = field['tensor-spec']['dtype']\n",
    "                field_type = f'tensor[{tensor_type}]'\n",
    "            else:\n",
    "                field_type = field[\"type\"]\n",
    "            if 'name' in field:\n",
    "                parameters.append(f'{field[\"name\"]} [{field_type}]')\n",
    "            else:\n",
    "                parameters.append(f'[{field_type}]')\n",
    "        return parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffa81ca3-9ab7-423f-b254-7f38f19d63d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# extract_run_artifact_flavors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25ce5bb9-5542-4d26-808f-339eea7ff3a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "   def extract_run_artifact_flavors(flavors):\n",
    "        \"\"\"\n",
    "        Whether those are native python models or ML frameworks (keras, sklearn, xgboost), models may have been\n",
    "        serialized (pickled) using different flavors. We retrieve all artifacts logged together with their\n",
    "        interpreter version in order to guarantee model reproducibility.\n",
    "        :param flavors: The logged artifacts as MLFlow tags\n",
    "        :return: the list of logged artifacts, flavors and interpreter versions.\n",
    "        \"\"\"\n",
    "        logged_flavors = []\n",
    "        for flavor in flavors:\n",
    "            executor_type = flavor\n",
    "            version = list(filter(lambda x: x.endswith('version'), flavors[flavor].keys()))\n",
    "            if version:\n",
    "                executor_version = flavors[flavor][version[0]]\n",
    "            else:\n",
    "                executor_version = None\n",
    "            logged_flavors.append(ArtifactFlavor(executor_type, executor_version))\n",
    "        return logged_flavors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e34f0c5-8f17-4689-ad69-39e3c56214e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# extract_run_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02e6e44c-f2f0-4476-9c21-c3fed0cdd5c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_run_artifacts( run_tags):\n",
    "        \"\"\"\n",
    "        MLFlow captured all artifacts for the given model experiment. Artifacts may include model input and output\n",
    "        signatures as well as interpreter versions and ML frameworks.\n",
    "        :param run_tags: The tag captured on MLFlow as JSON string.\n",
    "        :return: the list of artifacts together with model signature\n",
    "        \"\"\"\n",
    "        model_info = run_tags['mlflow.log-model.history']\n",
    "        fmt = '%Y-%m-%d %H:%M:%S.%f'\n",
    "\n",
    "        if model_info:\n",
    "            artifacts = []\n",
    "            model_info = json.loads(model_info)\n",
    "            for model_logged in model_info:\n",
    "                created = datetime.datetime.strptime(model_logged['utc_time_created'], fmt)\n",
    "                if 'flavors' in model_logged:\n",
    "                    flavors = extract_run_artifact_flavors(model_logged['flavors'])\n",
    "                else:\n",
    "                    flavors = []\n",
    "                if 'signature' in model_logged:\n",
    "                    signature = model_logged['signature']\n",
    "                    signature_input = extract_run_artifact_signature(signature['inputs'])\n",
    "                    signature_output = extract_run_artifact_signature(signature['outputs'])\n",
    "                    signature = ArtifactSignature(signature_input, signature_output)\n",
    "                else:\n",
    "                    signature = None\n",
    "                artifacts.append(Artifact(created, flavors, signature))\n",
    "            return Artifacts(artifacts)\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8b132df-1791-40d8-90ae-38b3e492b8b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# extract_source_lineage_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5567082e-b3df-497c-94b3-12917750ef0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    def extract_source_lineage_name(data_source):\n",
    "        \"\"\"\n",
    "        Data lineage may return different upstream data sources. Only supporting tables for now, those sources\n",
    "        will include information of catalog, database and table. We could possibly extend this function to return\n",
    "        actual schema and column lineage, but let's keep it simple for now.\n",
    "        :param data_source: the source captured in data lineage from UC\n",
    "        :return: the parsed datasource returned in a 3 layer namespace form (catalog.database.table)\n",
    "        \"\"\"\n",
    "        if 'tableInfo' in data_source:\n",
    "            table_info = data_source['tableInfo']\n",
    "            coordinate = []\n",
    "            if 'catalog_name' in table_info:\n",
    "                coordinate.append(table_info['catalog_name'])\n",
    "            if 'schema_name' in table_info:\n",
    "                coordinate.append(table_info['schema_name'])\n",
    "            else:\n",
    "                coordinate.append('default')\n",
    "            if 'name' in table_info:\n",
    "                coordinate.append(table_info['name'])\n",
    "                return 'table', '.'.join(coordinate)\n",
    "            else:\n",
    "                logger.warning(\"No table name found, ignoring upstream\")\n",
    "        elif 'fileInfo' in data_source:\n",
    "            file_info = data_source['fileInfo']\n",
    "            file_path = file_info['path']\n",
    "            return 'path', file_path\n",
    "        else:\n",
    "            logger.warning(\"Unsupported format for source {}\".format(data_source.keys()))\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "532023db-ef6e-4815-9a98-8d8f98ebb595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# extract_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b65c49d0-687f-4aac-96d6-d267c03f0979",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    def extract_notebook(html_content):\n",
    "        \"\"\"\n",
    "        When exported as HTML, notebook contain multiple metadata, complex HTML, and actual notebook content stored\n",
    "        as base 64 encoded string. This function will retrieve only notebook content from HTML notebook.\n",
    "        :param html_content: the raw HTML content for exported notebook\n",
    "        :return: the actual notebook content as base 64 encoded, wrapped into a class for HTML display\n",
    "        \"\"\"\n",
    "        notebook_regex = re.compile(\n",
    "            \"DATABRICKS_NOTEBOOK_MODEL = '((?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?)'\"\n",
    "        )\n",
    "        matches = notebook_regex.findall(html_content)\n",
    "        if matches:\n",
    "            return Notebook(matches[0])\n",
    "        else:\n",
    "            logger.error(\"Could not extract notebook content from HTML\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "201deb0a-98b9-49ae-95e4-a335f7e18eb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# process_lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "230d4621-dbfc-43da-bc30-3acf27eb3e70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " def process_lineage( response):\n",
    "        \"\"\"\n",
    "        Extracting data lineage is a recursive process. For each data source, we need to extract information of\n",
    "        the source itself (the name, typically in 3 layer namespace) as well as its upstream sources. This will go\n",
    "        through the UC API again till no upstream source can be found. As UC will grow, we need to cover additional\n",
    "        requirement such as process lineage, dashboard lineage, etc.\n",
    "        :param response: the original response from UC API\n",
    "        :return: the result of the recursion for 1 given data source as a list of upstream dependencies.\n",
    "        \"\"\"\n",
    "        children = []\n",
    "        if 'upstreams' in response:\n",
    "            upstreams = response['upstreams']\n",
    "            for upstream in upstreams:\n",
    "                upstream_type, upstream_source = extract_source_lineage_name(upstream)\n",
    "                upstream_lineage = get_lineage_rec(upstream_source, upstream_type)\n",
    "                children.append(upstream_lineage)\n",
    "        return children\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6276227-b94a-42d9-923a-868a7655b258",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# process_model_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddb7a4a6-40b9-480c-a4af-c7bb36f09155",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    def process_model_parent(response):\n",
    "        \"\"\"\n",
    "        Core business logic to extract information from the model registered on MLFlow. This higher level taxonomy\n",
    "        should capture information around model owner, timestamp as well as all latest versions (for each stage).\n",
    "        :param response: the original JSON response from MLFlow API\n",
    "        :return: the metadata of model as registered on MLFlow together with raw information for each version\n",
    "        \"\"\"\n",
    "        #response = response['registered_model']\n",
    "        model_parent_owner = response['owner']\n",
    "        model_catalog = response['catalog_name']\n",
    "        model_schema = response['schema_name']\n",
    "        model_name = response['name']\n",
    "        model_parent_creation = parse_date(response['created_at'])\n",
    "        if 'description' not in response:\n",
    "            model_parent_description = None\n",
    "        else:\n",
    "            model_parent_description = ModelDescription(response['description'])\n",
    "        model_parent_tags = extract_tags(response)\n",
    "        model_parent_aliases = extract_aliases(response)\n",
    "\n",
    "        return ModelParent(\n",
    "            model_catalog,\n",
    "            model_schema,\n",
    "            model_name,\n",
    "            model_parent_description,\n",
    "            model_parent_tags,\n",
    "            model_parent_owner,\n",
    "            model_parent_creation,\n",
    "            model_parent_aliases\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45ef053b-4e76-4c59-91f4-5f5bede820b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# process_model_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c82b6b2d-2ac0-4ecd-978e-88e00572bc04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "   def process_model_run( response, run_id):\n",
    "        \"\"\"\n",
    "        Core business logic to extract information for a given model experiment. This 3rd layer taxonomy will contain\n",
    "        vital information about the technical context behind this model submission such as the cluster dependencies,\n",
    "        libraries and associated code. Depending on the type of processing (JOB or INTERACTIVE), we will pull the\n",
    "        relevant information and tags.\n",
    "        :param response: the original JSON response from MLFlow experiment tracker API\n",
    "        :param run_id: the experiment ID captured by MLFlow registry.\n",
    "        :return: the technical context surrounding this model submission, wrapped as class for HTML output.\n",
    "        \"\"\"\n",
    "\n",
    "        run_object = response['run']\n",
    "        run_data = run_object['data']\n",
    "        run_info = run_object['info']\n",
    "        run_tags = key_value_to_dict(run_data['tags'])\n",
    "\n",
    "        run_experiment_id = run_info['experiment_id']\n",
    "        run_timestamp = parse_time(run_info['start_time'])\n",
    "        run_parent_id = run_tags.get('mlflow.parentRunId') or None\n",
    "        run_description = run_tags.get('mlflow.note.content') or None\n",
    "        run_user = run_tags.get('mlflow.user') or None\n",
    "        run_workspace = run_tags.get('mlflow.databricks.workspaceURL') or None\n",
    "\n",
    "        run_data_sources = extract_run_data_sources(run_object, run_tags)\n",
    "        run_cluster = extract_run_cluster(run_tags)\n",
    "        run_artifacts = extract_run_artifacts(run_tags)\n",
    "        run_libraries = extract_run_libraries(run_tags)\n",
    "\n",
    "        if run_description:\n",
    "            run_description = ExperimentDescription(run_description)\n",
    "\n",
    "        if 'mlflow.source.type' in run_tags.keys():\n",
    "            source_type = run_tags.get('mlflow.source.type')\n",
    "            if source_type == 'NOTEBOOK':\n",
    "                # Pull associated notebook\n",
    "                # TODO: use revision ID\n",
    "                source_name = run_tags.get('mlflow.source.name')\n",
    "                source_code = get_notebook(source_name)\n",
    "                source_commit = run_tags.get('mlflow.databricks.notebookRevisionID')\n",
    "            elif source_type == 'JOB':\n",
    "                # Pull associated JOB output\n",
    "                source_name = run_tags.get('mlflow.source.name')\n",
    "                source_code = get_notebook_from_job(source_name)\n",
    "                source_commit = None\n",
    "            else:\n",
    "                source_name = None\n",
    "                source_code = None\n",
    "                source_commit = None\n",
    "\n",
    "            if 'mlflow.databricks.gitRepoUrl' in run_tags:\n",
    "                source_url = run_tags.get('mlflow.databricks.gitRepoUrl')\n",
    "                source_commit = run_tags.get('mlflow.databricks.gitRepoCommit')\n",
    "            else:\n",
    "                source_url = None\n",
    "        else:\n",
    "            source_type = None\n",
    "            source_name = None\n",
    "            source_commit = None\n",
    "            source_url = None\n",
    "            source_code = None\n",
    "\n",
    "        if 'params' in run_data:\n",
    "            run_params = ExperimentParameters(key_value_to_dict(run_data['params']))\n",
    "        else:\n",
    "            run_params = {}\n",
    "\n",
    "        if 'metrics' in run_data:\n",
    "            run_metrics = ExperimentMetrics(key_value_to_dict(run_data['metrics']))\n",
    "            # TODO: consider extracting metrics across runs or find way to vizualize in parallel graph\n",
    "        else:\n",
    "            run_metrics = {}\n",
    "\n",
    "        return ModelExperiment(\n",
    "            run_id,\n",
    "            run_description,\n",
    "            run_user,\n",
    "            run_workspace,\n",
    "            run_experiment_id,\n",
    "            run_timestamp,\n",
    "            run_params,\n",
    "            run_metrics,\n",
    "            run_data_sources,\n",
    "            run_parent_id,\n",
    "            source_type,\n",
    "            source_name,\n",
    "            source_url,\n",
    "            source_commit,\n",
    "            source_code,\n",
    "            run_cluster,\n",
    "            run_artifacts,\n",
    "            run_libraries\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb6afdc7-b070-4a63-b919-4c17f86403da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# process_model_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54281c4e-11d1-4f58-b97f-749101f23a5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " def process_model_versions(data, model_name, model_parent_aliases):\n",
    "        versions = []\n",
    "        for model_version in data: #data['model_versions']:\n",
    "            model_version=model_version.as_dict()\n",
    "            model_date = parse_date(model_version['created_at'])\n",
    "            user = model_version['created_by']\n",
    "            versions.append(ModelPreviousVersion(\n",
    "                model_version['version'],\n",
    "                model_date,\n",
    "                user,\n",
    "                model_parent_aliases.get(model_version['version'])\n",
    "            ))\n",
    "        return ModelVersions(model_name, versions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0c3a35a-20a9-4e24-bc95-c983bb297bbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# process_model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0723ea63-5fee-4449-9f62-8dbe9dccb6dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    def process_model_version(data, model_version):\n",
    "        \"\"\"\n",
    "        Core business logic to extract information from a given model version. This secondary level taxonomy should\n",
    "        capture information about model submitter, the submission data as well as the desired transition state (e.g.\n",
    "        from STAGING to PROD).\n",
    "        :param data: the original JSON response from MLFlow API\n",
    "        :param model_version: the version of the model to fetch from MLFlow transition API.\n",
    "        :return: the metadata of the model version as submitted by end user, wrapped as class for HTML output.\n",
    "        \"\"\"\n",
    "        #data = data['model_version']\n",
    "        if 'description' not in data:\n",
    "            description = None\n",
    "        else:\n",
    "            description = ModelDescription(data['description'])\n",
    "        return ModelSubmission(\n",
    "            description,\n",
    "            data['created_by'], #data['user_id']\n",
    "            model_version,\n",
    "            parse_time(data['created_at']), #data['creation_timestamp']\n",
    "            data['run_id'],\n",
    "            extract_tags(data)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a428cd34-db47-4e2c-bf72-55c4025b93fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# get_model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3f78f0a-1e0f-4ca2-b044-abee1da8f597",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    def get_model_version_old(self, model_name, model_version):\n",
    "        \"\"\"\n",
    "        Entry point for a given model risk management submission. We retrieve information surrounding a particular\n",
    "        version of a model as registered on MLFlow. Note that this version should be the latest available for a given\n",
    "        stage (e.g. STAGING).\n",
    "        :param model_name: the name of the model to fetch from MLFlow API.\n",
    "        :param model_version: the version of the model to fetch from MLFlow API response (optional).\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        logger.info(f'Retrieving version [{model_version}] for model [{model_name}]')\n",
    "        url = f'{base_url}/api/2.1/mlflow/unity-catalog/model-versions/get?name={model_name}&version={model_version}'\n",
    "        data = submit_api_call(url)\n",
    "        return process_model_version(data, model_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d8be7b3-28b1-4cef-8851-be8bb2bded54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_model_version(model_name, model_version):\n",
    "        \"\"\"\n",
    "        Entry point for a given model risk management submission. We retrieve information surrounding a particular\n",
    "        version of a model as registered on MLFlow. Note that this version should be the latest available for a given\n",
    "        stage (e.g. STAGING).\n",
    "        :param model_name: the name of the model to fetch from MLFlow API.\n",
    "        :param model_version: the version of the model to fetch from MLFlow API response (optional).\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        logger.info(f'Retrieving version [{model_version}] for model [{model_name}]')\n",
    "        w = WorkspaceClient()\n",
    "#        model = w.registered_models.get(model_name)\n",
    "        model_d=w.model_versions.get(model_name, model_version).as_dict() \n",
    "#        z=process_model_parent(model.as_dict())\n",
    "#        model_version = w.model_versions.list(model_name)\n",
    "        return process_model_version(model_d, model_version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "854ec9c2-e1ba-49b2-a12a-e37805000669",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# get_model_versions\n",
    "\n",
    "API version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c030d63-c1d1-4cde-8874-0664e49d81a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_model_versions_old( model_name, model_parent_aliases):\n",
    "        logger.info(f'Retrieving versions for model [{model_name}]')\n",
    "        url = f'{base_url}/api/2.1/unity-catalog/models/{model_name}/versions'\n",
    "        data = submit_api_call(url)\n",
    "        return process_model_versions(data, model_name, model_parent_aliases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83b1fc14-376c-4dfc-8022-21f68edf6c04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_model_versions( model_name, model_parent_aliases):\n",
    "        logger.info(f'Retrieving versions for model [{model_name}]')\n",
    "        w = WorkspaceClient()\n",
    "        model = w.registered_models.get(model_name)\n",
    "        model_d=model.as_dict() \n",
    "        z=process_model_parent(model.as_dict())\n",
    "        data = w.model_versions.list(model_name)        \n",
    "        return process_model_versions(data, model_name, model_parent_aliases)\n",
    "      \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72fc3740-f8ca-4e69-90c8-18fafcbb6f23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# get_model_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0086676f-86b9-4470-ad88-7ed1ee057e41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    def get_model_parent_old( model_name):\n",
    "        \"\"\"\n",
    "        Entry point for a given Model risk management output. We pulled information from MLFlow registry server for a\n",
    "        given model name, regardless of its desired version. Information returned will include business context around\n",
    "        our model such as creation timestamp, model owner, etc.\n",
    "        :param model_name: the name of the model to fetch from MLFlow API.\n",
    "        :return: The business context surrounding our model, as captured by MLFlow directly or filled by end user.\n",
    "        \"\"\"\n",
    "        logger.info(f'Retrieving model [{model_name}]')\n",
    "        url = f'{base_url}/api/2.1/mlflow/unity-catalog/registered-models/get?name={model_name}'\n",
    "        data = submit_api_call(url)\n",
    "        return process_model_parent(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63b588d6-062c-40f6-a341-4a54171633eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " def get_model_parent( model_name):\n",
    "        \"\"\"\n",
    "        Entry point for a given Model risk management output. We pulled information from MLFlow registry server for a\n",
    "        given model name, regardless of its desired version. Information returned will include business context around\n",
    "        our model such as creation timestamp, model owner, etc.\n",
    "        :param model_name: the name of the model to fetch from MLFlow API.\n",
    "        :return: The business context surrounding our model, as captured by MLFlow directly or filled by end user.\n",
    "        \"\"\"\n",
    "        logger.info(f'Retrieving model [{model_name}]')\n",
    "        w = WorkspaceClient()\n",
    "        model = w.registered_models.get(model_name)\n",
    "        data=model.as_dict() \n",
    "        return process_model_parent(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8169d493-82d8-4447-bbd1-10eb69152b30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# get_model_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95eef098-41eb-4f7a-b538-76ff8ba48062",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_model_run_old(run_id):\n",
    "        \"\"\"\n",
    "        Entry point for a given model experiment. Querying the MLFlow tracker API, we aim at extracting all technical\n",
    "        context surrounding a given model registered on MLFlow, including notebook, data sources, cluster dependencies\n",
    "        :param run_id: the ID of the experiment to fetch from MLFlow\n",
    "        :return: the technical context surrounding a given model, returned as wrapped class for HTML output\n",
    "        \"\"\"\n",
    "        logger.info(f'Retrieving run_id [{run_id}] associated to model')\n",
    "        url = f'{base_url}/api/2.1/mlflow/runs/get?run_id={run_id}'\n",
    "        data = submit_api_call(url)\n",
    "        return process_model_run(data, run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fc51fa5-2442-4f0e-8779-f1d6983282b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_model_run(run_id):\n",
    "        \"\"\"\n",
    "        Entry point for a given model experiment. Querying the MLFlow tracker API, we aim at extracting all technical\n",
    "        context surrounding a given model registered on MLFlow, including notebook, data sources, cluster dependencies\n",
    "        :param run_id: the ID of the experiment to fetch from MLFlow\n",
    "        :return: the technical context surrounding a given model, returned as wrapped class for HTML output\n",
    "        \"\"\"\n",
    "        logger.info(f'Retrieving run_id [{run_id}] associated to model')\n",
    "        w = WorkspaceClient()\n",
    "        response = w.experiments.get_run(run_id)\n",
    "        data=response.as_dict() \n",
    "        return process_model_run(data, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b13e7e3-f720-4641-b6ea-477e29a4089d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# get_lineage_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2673fb2b-3c6f-4182-a8cc-efebdfea8539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    def get_lineage_rec_old(upstream_source, upstream_type):\n",
    "        \"\"\"\n",
    "        Querying the UC API, we retrieve all data lineage for each data source captured on MLFlow experiment. This\n",
    "        requires call that same API recursively to fetch all upstream dependencies.\n",
    "        :param upstream_source: the name of the data source to fetch from table API, in the form of 3 layer namespace\n",
    "        :param upstream_type: the type of the data source to fetch from table API, in the form of 3 layer namespace\n",
    "        :return: the entire upstream lineage wrapped as a class for HTML output\n",
    "        \"\"\"\n",
    "        children = []\n",
    "        url = f'{base_url}/api/2.1/lineage-tracking/table-lineage?table_name={upstream_source}'\n",
    "        if upstream_type == 'delta':\n",
    "            response = json.loads(requests.get(url=url, headers=headers).text)\n",
    "            if 'error_code' in response:\n",
    "                logger.error(f\"Error in lineage response, {response['message']}\")\n",
    "            else:\n",
    "                children = process_lineage(response)\n",
    "        return LineageDataSource(upstream_source, upstream_type, children)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f59ca496-8000-4d26-82ad-5710e650fbc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_lineage_rec(upstream_source, upstream_type):\n",
    "        \"\"\"\n",
    "        Querying the UC SDK, we retrieve all data lineage for each data source captured on MLFlow experiment. This\n",
    "        requires call that same SDK recursively to fetch all upstream dependencies.\n",
    "        :param upstream_source: the name of the data source to fetch from table SDK, in the form of 3 layer namespace\n",
    "        :param upstream_type: the type of the data source to fetch from table SDK, in the form of 3 layer namespace\n",
    "        :return: the entire upstream lineage wrapped as a class for HTML output\n",
    "        \"\"\"\n",
    "        children = []\n",
    "        logger.info(f'Retrieving model [{model_name}]')\n",
    "        w = WorkspaceClient()\n",
    "        model = w.registered_models.get(model_name)\n",
    "        data=model.as_dict() \n",
    "        if upstream_type == 'delta':\n",
    "            response = json.loads(requests.get(url=url, headers=headers).text)\n",
    "            if 'error_code' in response:\n",
    "                logger.error(f\"Error in lineage response, {response['message']}\")\n",
    "            else:\n",
    "                children = process_lineage(response)\n",
    "        return LineageDataSource(upstream_source, upstream_type, children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "124bcc3d-d2b2-4ae4-a4d4-3df6b3f56a8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# get_lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d578e217-6f4d-4ea2-b406-74aa17f59fb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    def get_lineage(data_source_names, model_name):\n",
    "        \"\"\"\n",
    "        Entry point for data lineage, we wrapped all data sources and their lineage into a class object to facilitate\n",
    "        HTML creation at later stage\n",
    "        :param data_source_names: the list of all source of data captured by MLFlow and available as such on UC\n",
    "        :return: the entire upstream lineage wrapped as a class for HTML output\n",
    "        \"\"\"\n",
    "        logger.info(f'Retrieving data lineage for {len(data_source_names)} data source(s)')\n",
    "        return Lineage([get_lineage_rec(data_source_name, data_source_type) for data_source_name, data_source_type in data_source_names], model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba3f9548-7a0c-4535-a8bc-c68db0b40a1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# get_notebook_from_job\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b867e52-d11d-4cd6-9b8c-ceba4b8bcc40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "   def get_notebook_from_job_old( job_id):\n",
    "        \"\"\"\n",
    "        Querying the JOB API, we aim at extracting notebook content associated with a MLFlow experiment.\n",
    "        :param job_id: the ID of job to fetch notebook output from\n",
    "        :return: the notebook content returned as encoded base 64\n",
    "        \"\"\"\n",
    "        run_id = job_id.split('/')[-1]\n",
    "        url = f'{base_url}/api/2.1/jobs/runs/export?run_id={run_id}&views_to_export=CODE'\n",
    "        response = json.loads(requests.get(url=url, headers=headers).text)\n",
    "        if 'error_code' in response:\n",
    "            logger.error(f\"Error in job response, {response['message']}\")\n",
    "            return None\n",
    "        content = list(filter(lambda x: x['type'] == 'NOTEBOOK', response['views']))\n",
    "        if len(content) > 0:\n",
    "            html_org_content = content[0]['content']\n",
    "            return extract_notebook(html_org_content)\n",
    "        else:\n",
    "            logger.error(f\"Could not find any output content for job [{job_id}]\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbb1e04f-f7ff-4d7c-89d7-d85ba39b2bb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "   def get_notebook_from_job( job_id):\n",
    "        \"\"\"\n",
    "        Querying the JOB API, we aim at extracting notebook content associated with a MLFlow experiment.\n",
    "        :param job_id: the ID of job to fetch notebook output from\n",
    "        :return: the notebook content returned as encoded base 64\n",
    "        \"\"\"\n",
    "        run_id = job_id.split('/')[-1]\n",
    "        w = WorkspaceClient()\n",
    "\n",
    "        response = w.jobs.export_run(run_id)\n",
    "        data=response.as_dict()\n",
    "        \n",
    "#        response = json.loads(requests.get(url=url, headers=headers).text)\n",
    "        if data.get('error_code') is not None :\n",
    "            logger.error(f\"Error in job response, {data['message']}\")\n",
    "            return None\n",
    "        content = list(filter(lambda x: x['type'] == 'NOTEBOOK', data['views']))\n",
    "        if len(content) > 0:\n",
    "            html_org_content = content[0]['content']\n",
    "            return extract_notebook(html_org_content)\n",
    "        else:\n",
    "            logger.error(f\"Could not find any output content for job [{job_id}]\")\n",
    "            print(f\"Could not find any output content for job [{job_id}]\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4154f32-cf8e-4a00-92d4-06a0db213ae8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# get_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a084215-552f-47c1-ad62-8b784bd3020a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_notebook_old(remote_path):\n",
    "        \"\"\"\n",
    "        Querying the workspace API, we aim at extracting notebook content associated with a MLFlow experiment.\n",
    "        :param remote_path: the path of the notebook to fetch\n",
    "        :return: the notebook content returned as encoded base 64\n",
    "        \"\"\"\n",
    "        logger.info(f'Retrieving notebook [{remote_path}] associated to model run')\n",
    "        url = f'{base_url}/api/2.1/workspace/export?path={remote_path}&format=HTML&direct_download=False'\n",
    "        response = json.loads(requests.get(url=url, headers=headers).text)\n",
    "        if 'error_code' in response:\n",
    "            logger.error(f\"Error in notebook response, {response['message']}\")\n",
    "            return None\n",
    "        html_org_content = str(base64.b64decode(response['content']), 'utf-8')\n",
    "        return extract_notebook(html_org_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "959ea56b-d3db-44cb-aab1-61f6eacffcd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_notebook(remote_path):\n",
    "        \"\"\"\n",
    "        Querying the workspace API, we aim at extracting notebook content associated with a MLFlow experiment.\n",
    "        :param remote_path: the path of the notebook to fetch\n",
    "        :return: the notebook content returned as encoded base 64\n",
    "        \"\"\"\n",
    "        logger.info(f'Retrieving notebook [{remote_path}] associated to model run')\n",
    "\n",
    "        from databricks.sdk.service import workspace\n",
    "        w = WorkspaceClient()\n",
    "        #notebook = f\"/Users/{w.current_user.me().user_name}/sdk-{time.time_ns()}\"\n",
    "\n",
    "        \n",
    "        export_response = w.workspace.export(format=workspace.ExportFormat.HTML, path=remote_path)\n",
    "\n",
    "        html_org_content=export_response.content \n",
    "\n",
    "        return extract_notebook(html_org_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb600bf4-902d-498f-a3d3-562712ce4e9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# generate_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f6b46da-897c-47b9-81a0-de3d7156f474",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "    def generate_doc(model_name, model_version, output_file=None, verbatim_file=None):\n",
    "        \"\"\"\n",
    "        Public entry point for model risk management PDF output. Given a model name, an optional model version and a\n",
    "        target output file, we will fetch all the required information from various databricks API, bring that\n",
    "        technical and business context together and generate PDF output accordingly. After multiple consideration\n",
    "        being the use of e.g. LateX library, we decided to leverage HTML as main format as it supports markdown\n",
    "        information, HTML that we can \"beautify\" using boostrap CSS and convert to PDF document.\n",
    "        :param model_name: the name of the model to fetch from databricks\n",
    "\n",
    "        :param model_version: the version of the model to fetch from databricks\n",
    "        :param output_file: the output file to write PDF document if omitted then it will only be displayed in the cell (the default)\n",
    "        :param verbatim_file: giving user the opportunity to supply their own verbatim files instead of default\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if model_version:\n",
    "            logger.info(f'Generating MRM output for model [{model_name}] (v{model_version})')\n",
    "        else:\n",
    "            logger.info(f'Generating MRM output for latest model [{model_name}]')\n",
    "\n",
    "        # load our text\n",
    "        verbatim = load_verbatim(verbatim_file)\n",
    "\n",
    "        # retrieve model from Unity Catalog\n",
    "        model_parent = get_model_parent(model_name)\n",
    "        model_versions = get_model_versions(model_name, model_parent.model_parent_aliases)\n",
    "        model_version = get_model_version(model_name, model_version)\n",
    "        model_run = get_model_run(model_version.model_run_id)\n",
    "\n",
    "        # retrieve model data input and lineage\n",
    "        if model_run.run_data_sources:\n",
    "            data_sources = model_run.run_data_sources\n",
    "            data_lineage = None #get_lineage(data_sources.sources(), model_name)\n",
    "        else:\n",
    "            data_sources = None\n",
    "            data_lineage = None\n",
    "\n",
    "        ##########################################################################################\n",
    "        # FRONT PAGE OF OUR REPORT\n",
    "        ##########################################################################################\n",
    "\n",
    "        html = [\n",
    "            f'<h1 class=\"text-center\">{verbatim[\"title\"]}</h1>',\n",
    "            '<h3 class=\"card-subtitle text-muted text-center\">{}</h3>'.format(model_name.split('.')[-1]),\n",
    "        ]\n",
    "\n",
    "        ##########################################################################################\n",
    "        # TOP LEVEL SECTION\n",
    "        # Include information about model ownership and description\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-break section-content\">',\n",
    "            f'<h1>{verbatim[\"mlflow_model\"][\"header\"]}</h1>',\n",
    "            f'<p>{verbatim[\"mlflow_model\"][\"info\"]}</p>',\n",
    "            a_bit_of_space\n",
    "        ])\n",
    "\n",
    "        html.extend(model_parent.to_html(h_level=1))\n",
    "        html.append(a_little_bit_of_space)\n",
    "\n",
    "        if model_parent.model_description:\n",
    "            html.append('<small class=\"text-muted\">description from mlflow registry</small>')\n",
    "            html.extend(model_parent.model_description.to_html(h_level=2))\n",
    "        else:\n",
    "            html.extend([\n",
    "                '<div class=\"alert alert-warning section-content\" role=\"alert\">',\n",
    "                f'<p>{verbatim[\"mlflow_model\"][\"error\"]}</p>',\n",
    "                '</div>'\n",
    "            ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL HISTORY SECTION\n",
    "        # Include model submission request, triggering independent validation\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-break section-content\">',\n",
    "            f'<h1>{verbatim[\"mlflow_model_versions\"][\"header\"]}</h1>',\n",
    "            f'<p>{verbatim[\"mlflow_model_versions\"][\"info\"]}</p>',\n",
    "            a_bit_of_space\n",
    "        ])\n",
    "\n",
    "        html.extend(model_versions.to_html(h_level=1))\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL SUBMISSION SECTION\n",
    "        # Include model submission request, triggering independent validation\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-break section-content\">',\n",
    "            f'<h1>{verbatim[\"mlflow_model_version\"][\"header\"]}</h1>',\n",
    "            f'<p>{verbatim[\"mlflow_model_version\"][\"info\"]}</p>',\n",
    "            a_bit_of_space\n",
    "        ])\n",
    "\n",
    "        html.extend(model_version.to_html(h_level=1))\n",
    "        html.append(a_little_bit_of_space)\n",
    "        if model_version.model_description:\n",
    "            html.append('<small class=\"text-muted\">description from mlflow registry</small>')\n",
    "            html.extend(model_version.model_description.to_html(h_level=2))\n",
    "        else:\n",
    "            html.extend([\n",
    "                '<div class=\"alert alert-warning section-content\" role=\"alert\">',\n",
    "                f'<p>{verbatim[\"mlflow_model_version\"][\"error\"]}</p>',\n",
    "                '</div>'\n",
    "            ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL EXPERIMENT SECTION\n",
    "        # This section will get into the weeds of the experiment itself, technical context\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-break section-content\">',\n",
    "            f'<h1>{verbatim[\"mlflow_model_version_run\"][\"header\"]}</h1>',\n",
    "            f'<p>{verbatim[\"mlflow_model_version_run\"][\"info\"]}</p>',\n",
    "            a_bit_of_space\n",
    "        ])\n",
    "\n",
    "        html.extend(model_run.to_html(h_level=1))\n",
    "        html.append(a_little_bit_of_space)\n",
    "        if model_run.run_description:\n",
    "            html.append('<small class=\"text-muted\">description from mlflow experiment</small>')\n",
    "            html.extend(model_run.run_description.to_html(h_level=2))\n",
    "        else:\n",
    "            html.extend([\n",
    "                '<div class=\"alert alert-warning section-content\" role=\"alert\">',\n",
    "                f'<p>{verbatim[\"mlflow_model_version_run\"][\"error\"]}</p>',\n",
    "                '</div>'\n",
    "            ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL IMPLEMENTATION HEADER\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-break section-content\">',\n",
    "            f'<h1>{verbatim[\"implementation\"][\"header\"]}</h1>',\n",
    "            f'<p>{verbatim[\"implementation\"][\"info\"]}</p>',\n",
    "            '</div>'\n",
    "        ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL ARTIFACTS\n",
    "        # We list all artifacts logged alongside our model\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-content\">',\n",
    "            f'<h2>{verbatim[\"implementation_artifacts\"][\"header\"]}</h2>',\n",
    "            f'<p>{verbatim[\"implementation_artifacts\"][\"info\"]}</p>',\n",
    "            '</div>'\n",
    "        ])\n",
    "        if model_run.run_artifacts:\n",
    "            html.extend(model_run.run_artifacts.to_html(h_level=3))\n",
    "        else:\n",
    "            html.extend([\n",
    "                '<div class=\"alert alert-warning section-content\" role=\"alert\">',\n",
    "                f'<p>{verbatim[\"implementation_artifacts\"][\"error\"]}</p>'\n",
    "                '</div>'\n",
    "            ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL NOTEBOOKS\n",
    "        # We report the output of the job / notebook to bring all necessary context\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-break section-content\">',\n",
    "            f'<h2>{verbatim[\"implementation_approach\"][\"header\"]}</h2>',\n",
    "            f'<p>{verbatim[\"implementation_approach\"][\"info\"]}</p>',\n",
    "            '</div>'\n",
    "        ])\n",
    "        if model_run.source_code:\n",
    "            html.extend(model_run.source_code.to_html(h_level=2))\n",
    "        else:\n",
    "            html.extend([\n",
    "                '<div class=\"alert alert-warning section-content\" role=\"alert\">',\n",
    "                f'<p>{verbatim[\"implementation_approach\"][\"error\"]}</p>'\n",
    "                '</div>'\n",
    "            ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL PARAMETERS\n",
    "        # We report all parameters logged on mlflow, either programmatically (autologging) or not\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-break section-content\">',\n",
    "            f'<h2>{verbatim[\"model_parameters\"][\"header\"]}</h2>',\n",
    "            f'<p>{verbatim[\"model_parameters\"][\"info\"]}</p>',\n",
    "            '</div>'\n",
    "        ])\n",
    "        if model_run.run_params:\n",
    "            html.extend(model_run.run_params.to_html(h_level=3))\n",
    "        else:\n",
    "            html.extend([\n",
    "                '<div class=\"alert alert-warning section-content\" role=\"alert\">',\n",
    "                f'<p>{verbatim[\"model_parameters\"][\"error\"]}</p>'\n",
    "                '</div>'\n",
    "            ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL METRICS\n",
    "        # We report all metrics logged on mlflow, either programmatically (autologging) or not\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-break section-content\">',\n",
    "            f'<h2>{verbatim[\"model_metrics\"][\"header\"]}</h2>',\n",
    "            f'<p>{verbatim[\"model_metrics\"][\"info\"]}</p>',\n",
    "            '</div>'\n",
    "        ])\n",
    "        if model_run.run_metrics:\n",
    "            html.extend(model_run.run_metrics.to_html(h_level=3))\n",
    "        else:\n",
    "            html.extend([\n",
    "                '<div class=\"alert alert-warning section-content\" role=\"alert\">',\n",
    "                f'<p>{verbatim[\"model_metrics\"][\"error\"]}</p>'\n",
    "                '</div>'\n",
    "            ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL DEPENDENCIES HEADER\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-break section-content\">',\n",
    "            f'<h1>{verbatim[\"model_dependencies\"][\"header\"]}</h1>',\n",
    "            f'<p>{verbatim[\"model_dependencies\"][\"info\"]}</p>',\n",
    "            '</div>'\n",
    "        ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL INFRASTRUCTURE SECTION\n",
    "        # We report infrastructure dependency of our model\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-content\">',\n",
    "            f'<h2>{verbatim[\"model_dependencies_infra\"][\"header\"]}</h2>',\n",
    "            f'<p>{verbatim[\"model_dependencies_infra\"][\"info\"]}</p>',\n",
    "            '</div>'\n",
    "        ])\n",
    "        if model_run.run_cluster:\n",
    "            html.extend(model_run.run_cluster.to_html(h_level=2))\n",
    "        else:\n",
    "            html.extend([\n",
    "                '<div class=\"alert alert-warning section-content\" role=\"alert\">',\n",
    "                f'<p>{verbatim[\"model_dependencies_infra\"][\"info\"]}</p>'\n",
    "                '</div>'\n",
    "            ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL LIBRARY SECTION\n",
    "        # We report all libraries logged alongside our model\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-content\">',\n",
    "            f'<h2>{verbatim[\"model_dependencies_libraries\"][\"header\"]}</h2>',\n",
    "            f'<p>{verbatim[\"model_dependencies_libraries\"][\"info\"]}</p>',\n",
    "            '</div>'\n",
    "        ])\n",
    "\n",
    "        if model_run.run_libraries and model_run.run_libraries.non_empty():\n",
    "            html.extend(model_run.run_libraries.to_html(h_level=2))\n",
    "        else:\n",
    "            html.extend([\n",
    "                '<div class=\"alert alert-warning section-content\" role=\"alert\">',\n",
    "                f'<p>{verbatim[\"model_dependencies_libraries\"][\"error\"]}</p>'\n",
    "                '</div>'\n",
    "            ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL SIGNATURE SECTION\n",
    "        # We report all model input and output signature\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-break section-content\">',\n",
    "            f'<h2>{verbatim[\"model_signature\"][\"header\"]}</h2>',\n",
    "            f'<p>{verbatim[\"model_signature\"][\"info\"]}</p>',\n",
    "            '</div>'\n",
    "        ])\n",
    "        if model_run.run_artifacts:\n",
    "            for artifact in model_run.run_artifacts.artifacts:\n",
    "                if artifact.signature:\n",
    "                    html.extend(artifact.signature.to_html(h_level=3))\n",
    "        else:\n",
    "            html.extend([\n",
    "                '<div class=\"alert alert-warning section-content\" role=\"alert\">',\n",
    "                f'<p>{verbatim[\"model_signature\"][\"error\"]}</p>'\n",
    "                '</div>'\n",
    "            ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL DATA DEPENDENCY SECTION\n",
    "        # We report all data sources logged on MLFlow\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-content\">',\n",
    "            f'<h2>{verbatim[\"model_dependencies_data\"][\"header\"]}</h2>',\n",
    "            f'<p>{verbatim[\"model_dependencies_data\"][\"info\"]}</p>',\n",
    "            '</div>'\n",
    "        ])\n",
    "\n",
    "        if data_sources:\n",
    "            html.extend(data_sources.to_html(h_level=2))\n",
    "        else:\n",
    "            html.extend([\n",
    "                '<div class=\"alert alert-warning section-content\" role=\"alert\">',\n",
    "                f'<p>{verbatim[\"model_dependencies_data\"][\"error\"]}</p>'\n",
    "                '</div>'\n",
    "            ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # MODEL DATA LINEAGE SECTION\n",
    "        # We report a graph representation of our data lineage\n",
    "        ##########################################################################################\n",
    "\n",
    "        html.extend([\n",
    "            '<div class=\"section section-break section-content\">',\n",
    "            f'<h2>{verbatim[\"model_dependencies_lineage\"][\"header\"]}</h2>',\n",
    "            f'<p>{verbatim[\"model_dependencies_lineage\"][\"info\"]}</p>',\n",
    "            '</div>'\n",
    "        ])\n",
    "\n",
    "        if data_lineage:\n",
    "            html.extend(data_lineage.to_html())\n",
    "        else:\n",
    "            html.extend([\n",
    "                '<div class=\"alert alert-warning section-content\" role=\"alert\">',\n",
    "                f'<p>{verbatim[\"model_dependencies_lineage\"][\"error\"]}</p>'\n",
    "                '</div>'\n",
    "            ])\n",
    "\n",
    "        ##########################################################################################\n",
    "        # GENERATE PDF OUTPUT\n",
    "        # We pimp our HTML with additional CSS and HTML template and generate PDF accordingly\n",
    "        ##########################################################################################\n",
    "        \n",
    "\n",
    "\n",
    "        # Create PDF\n",
    "        str=''.join(html)\n",
    "        html_out=HTML(string=str)\n",
    "        if output_file:\n",
    "            html_out.write_pdf(output_file)\n",
    "        displayHTML(str)\n",
    "\n",
    "        ##########################################################################################\n",
    "        # UPLOAD MODEL PDF TO VERSION\n",
    "        ##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a461ced-7a10-4d80-af78-1b705dd89d50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "mdtex2html",
     "pdfkit",
     "graphviz",
     "weasyprint",
     "mlflow"
    ],
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6273976864656039,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "MRM-Functions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
